{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_url='https://www.ratemds.com/best-doctors/ny/buffalo/family-gp/?page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-42ab61f010c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Import Data structure libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "from selenium import webdriver\n",
    "\n",
    "#Import Data structure libraries\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "#Import libraries for controlling crawling rate\n",
    "from time import sleep, time\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e57f6293b264>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0muser_pages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "user_pages=2\n",
    "pages=np.arange(1,int(user_pages)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.DataFrame(columns=['Doctor Name','Specialty','Overall Rating','No. of Reviews','Reviews', 'Review Rating'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in pages:\n",
    "\n",
    "    url=user_url+str(page)\n",
    "    \n",
    "    #Launch a Chrome Session\n",
    "    driver=webdriver.Chrome()\n",
    "    driver.implicitly_wait(30)\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Get the contents of webpage\n",
    "    r=get(url)\n",
    "    soup1=BeautifulSoup(r.content,'lxml')\n",
    "    \n",
    "    #Use loop to get into each doctor one by one\n",
    "    for i in soup1.findAll('a',{'class':'search-item-doctor-link'}):\n",
    "        name=i.text\n",
    "        \n",
    "        #Click on the doctor name\n",
    "        python_button=driver.find_element_by_link_text(name)\n",
    "        python_button.click()\n",
    "        \n",
    "        #Used to pause the scraping process for few seconds\n",
    "        sleep(randint(5,9))\n",
    "        \n",
    "        #Get the contents of the new page\n",
    "        soup=BeautifulSoup(driver.page_source,'lxml')\n",
    "        \n",
    "        #Extract the details\n",
    "        doctor_name=soup.find('h1',{'itemprop':'name'})\n",
    "    \n",
    "        specialty=soup.find('div',{'class':'search-item-info'})\n",
    "    \n",
    "        star_rating=soup.find('span',{'class':'star-rating'})\n",
    "        \n",
    "        no_of_reviews=soup.find('span',{'itemprop':'ratingCount'})\n",
    "        \n",
    "        #Get the html content of reviews and review ratings present on first page\n",
    "        soup4=soup.findAll('div',{'class':'rating'})\n",
    "        \n",
    "        #Extract the reviews and review ratings one by one and append it in the table\n",
    "        for k in range(len(soup4)):\n",
    "            reviews=soup4[k].find('p',{'itemprop':'reviewBody'})\n",
    "            review_rating=soup4[k].find('span',{'class':'star-rating'})\n",
    "            \n",
    "            df=df.append(pd.Series([doctor_name.text,specialty.text,star_rating['title'],no_of_reviews.text,reviews.text,review_rating['title']],index=df.columns), ignore_index=True)\n",
    "        \n",
    "        #If there are more than one pages of reviews and review ratings, get the number of pages\n",
    "        soup2=soup.find('ul',{'class':'pagination pagination-sm'})\n",
    "        soup3=soup2.findAll('a')\n",
    "        \n",
    "        #Click on each page number one by one and extract the reviews and review ratings\n",
    "        for l in range(2,len(soup3)):\n",
    "            python_button=driver.find_element_by_link_text(str(l))\n",
    "            python_button.click()\n",
    "            sleep(randint(5,9))\n",
    "            \n",
    "            soup5=BeautifulSoup(driver.page_source,'lxml')\n",
    "            soup6=soup5.findAll('div',{'class':'rating'})\n",
    "            \n",
    "            for k in range(len(soup6)):\n",
    "                reviews=soup6[k].find('p',{'itemprop':'reviewBody'})\n",
    "                review_rating=soup6[k].find('span',{'class':'star-rating'})\n",
    "                   \n",
    "                df=df.append(pd.Series([doctor_name.text,specialty.text,star_rating['title'],no_of_reviews.text,reviews.text,review_rating['title']],index=df.columns), ignore_index=True)\n",
    "            #Go back to the previous page\n",
    "            driver.execute_script(\"window.history.go(-1)\")   \n",
    "        #Go back to the main dr's list page          \n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "#Close the browser session\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
